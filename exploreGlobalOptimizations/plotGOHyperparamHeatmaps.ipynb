{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROOT_DIR /usr/WS2/bolet1/ruby-benchmarks/exploreGlobalOptimizations\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from benchmarks import *\n",
    "import glob\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ruby /usr/WS2/bolet1/ruby-benchmarks/exploreGlobalOptimizations\n"
     ]
    }
   ],
   "source": [
    "MACHINE = 'lassen' if 'lassen' in ROOT_DIR else 'ruby'\n",
    "print(MACHINE, ROOT_DIR)\n",
    "prognames = list(progs.keys())\n",
    "probsizes = ['smlprob', 'medprob', 'lrgprob']\n",
    "\n",
    "goMethods=['cma', 'pso', 'bo']\n",
    "seeds = [1337, 3827, 9999, 4873]\n",
    "\n",
    "hypers = {\n",
    "\t'cma':['popsize', ('sigma', 'seed')],\n",
    "\t'pso':[('popsize', 'w'), ('c1', 'c2', 'seed')],\n",
    "\t'bo-ucb':['kappa', 'seed']\n",
    "\t'bo-ei': ['xi', 'seed']\n",
    "\t'bo-poi':['xi', 'seed']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbFile = f'{MACHINE}-fullExploreDataset.csv'\n",
    "xtimeDB = pd.read_csv(ROOT_DIR+'/databases/'+dbFile)\n",
    "\n",
    "globalOptimals = xtimeDB.groupby(['progname', 'probsize'])['xtime'].min().reset_index()\n",
    "\n",
    "\n",
    "numthreads = 112 if MACHINE in 'ruby' else 160\n",
    "globalBaselines = xtimeDB.loc[(xtimeDB['OMP_NUM_THREADS'] == numthreads) \n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_PROC_BIND'] == 'close')\n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_PLACES'] == 'threads')\n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_SCHEDULE'] == 'static'),['progname', 'probsize', 'xtime']]\n",
    "\n",
    "probsizeMap = {'smlprob': 'Small Problem', 'medprob': 'Medium Problem', 'lrgprob': 'Large Problem'}\n",
    "prognameMap = {'bt_nas': 'BT', 'ft_nas': 'FT', 'hpcg': 'HPCG', 'lulesh':'Lulesh'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['c1', 'c2', 'globalSample', 'kappa', 'method', 'popsize', 'probsize',\n",
      "       'progname', 'seed', 'sigma', 'utilFnct', 'w', 'xi', 'xtime'],\n",
      "      dtype='object')\n",
      "c1 [ nan 0.1  0.45 0.8  1.15 1.5 ]\n",
      "c2 [ nan 0.1  0.45 0.8  1.15 1.5 ]\n",
      "kappa [ nan   2.   8.  15.  22.  29.  36.  42.  49.  56.  63.  70.  77.  83.\n",
      "  90.  97. 104. 111. 118. 124. 131. 138. 145. 152. 159. 165. 172. 179.\n",
      " 186. 193. 200.]\n",
      "method ['cma' 'pso' 'bo-ei' 'bo-ucb' 'bo-poi']\n",
      "popsize [ 3.  6.  9. 12. 15. 18. 21. 24. 27. 30. nan]\n",
      "probsize ['smlprob' 'medprob' 'lrgprob']\n",
      "progname ['bt_nas' 'ft_nas' 'hpcg' 'lulesh']\n",
      "seed [1337 3827 9999 4873]\n",
      "sigma [ 1.     4.222  7.444 10.667 13.889 17.111 20.333 23.556 26.778 30.\n",
      "    nan]\n",
      "w [  nan 0.1   0.325 0.55  0.775 1.   ]\n",
      "xi [  nan 0.    0.357 0.714 1.071 1.429 1.786 2.143 2.5   2.857 3.214 3.571\n",
      " 3.929 4.286 4.643 5.   ]\n"
     ]
    }
   ],
   "source": [
    "overallDF = pd.DataFrame()\n",
    "tojoin = []\n",
    "for progname in prognames:\n",
    "\tif progname == 'cg_nas' or progname == 'cfd_rodinia':\n",
    "\t\tcontinue\n",
    "\tfor method in goMethods:\n",
    "\t\t# read the pre-processed dataframes\n",
    "\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data-rawXtimes.csv'\n",
    "\t\tfullDF = pd.read_csv(filename)\n",
    "\t\ttojoin += [fullDF]\n",
    "\n",
    "overallDF = pd.concat(tojoin, ignore_index=True, sort=True)\n",
    "overallDF = overallDF.drop(['optimXtime', 'kappa_decay', 'kappa_decay_delay'], axis=1)\n",
    "\n",
    "print(overallDF.columns)\n",
    "overallDF.loc[overallDF['method'] == 'bo', 'method'] = overallDF[overallDF['method'] == 'bo'].apply(lambda x: x['method']+'-'+x['utilFnct'], axis=1)\n",
    "overallDF = overallDF.drop(['utilFnct'], axis=1)\n",
    "\n",
    "for col in overallDF:\n",
    "\tif col == 'xtime' or col == 'globalSample' or col == 'optimXtime':\n",
    "\t\tcontinue\n",
    "\tprint(col, overallDF[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeGOHyperHeatmapPlots(df, method):\n",
    "\n",
    "\tdf = df[df['method'] == method].reset_index()\n",
    "\n",
    "\t# we're going to make one plot for each GO method\n",
    "\t# want to show programs in rows, probsize in columns\n",
    "\n",
    "\t# the heatmap for each will show the hyperparameters on the two axes\n",
    "\t# the heatmap values will be the first globalSample that on average beats out the baseline\n",
    "\n",
    "\t# let's first make the tuples of columns\n",
    "\n",
    "\tg = sns.FacetGrid(df, row='progname', col='probsize', col_order=probsizes, palette='flare', height=10, aspect=1.5)\n",
    "\t#g.map_dataframe(drawHeatmap, annot=True, vmin=0.0, vmax=1.0, cbar=True)\n",
    "\tg.map_dataframe(drawHeatmap, annot=True, cbar=True)\n",
    "\n",
    "\n",
    "\tfor ax in g.axes.flatten():\n",
    "\t\tax.tick_params(axis='x', labelbottom=True, labelrotation=90)\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\n",
    "\tg.fig.subplots_adjust(top=0.96)\n",
    "\tg.fig.suptitle(f'OMP Hyperparam Exploration -- Speedups Over Baselines')\n",
    "\n",
    "\tplt.show()\n",
    "\n",
    "\t# for PSO we will need to make tuples\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "makeGOHyperHeatmapPlots(overallDF, 'cma')\n",
    "makeGOHyperHeatmapPlots(overallDF, 'pso')\n",
    "makeGOHyperHeatmapPlots(overallDF, 'bo-ucb')\n",
    "makeGOHyperHeatmapPlots(overallDF, 'bo-ei')\n",
    "makeGOHyperHeatmapPlots(overallDF, 'bo-poi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def makeOverallPlots(df, baselineXtimes=None):\n",
    "\t# want each row to be a program, and each column to be a problem size\n",
    "\t# each plot will show the average cumsum across each bo-util fnct, PSO, and CMA\n",
    "\n",
    "\totherCols = list(df.columns)\n",
    "\totherCols.remove('xtime')\n",
    "\totherCols.remove('globalSample')\n",
    "\tprint(otherCols)\n",
    "\n",
    "\t# for each category, we need to do a cumulative max\n",
    "\tdf['cummax'] = df.groupby(otherCols, dropna=False)['xtime'].transform('cummax')\n",
    "\n",
    "\tdef addBaselines(*args, **kwargs):\n",
    "\t\tdata = kwargs['data']\n",
    "\t\tprobsize = data.iloc[0]['probsize']\n",
    "\t\tprogname = data.iloc[0]['progname']\n",
    "\t\tmethod = data.iloc[0]['method']\n",
    "\n",
    "\t\tax = plt.gca()\n",
    "\t\thandles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "\t\toptimal = globalOptimals[(globalOptimals['progname'] == progname) & (globalOptimals['probsize'] == probsize)]['xtime'].iat[0]\n",
    "\t\tbaseline = globalBaselines[(globalBaselines['progname'] == progname) & (globalBaselines['probsize'] == probsize)]['xtime'].iat[0]\n",
    "\n",
    "\t\t#avrgCummax = data.groupby(['globalSample'], dropna=False)['cummax'].mean().reset_index()\n",
    "\t\t#if baselineXtimes is None:\n",
    "\t\t#\t#step = data[data['cummax'] >= 0.5]['globalSample'].min()\n",
    "\t\t#\tstep = avrgCummax[avrgCummax['cummax'] >= 0.5]['globalSample'].min()\n",
    "\t\t#\tif step is None:\n",
    "\t\t#\t\tprint(f'{progname} {probsize} {method} did not reach baseline')\n",
    "\t\t#\telse:\n",
    "\t\t#\t\tprint(f'{progname} {probsize} {method} passed baseline on step {step}')\n",
    "\t\t#else:\n",
    "\t\t#\tval = baselineXtimes.loc[(baselineXtimes['progname'] == progname) & (baselineXtimes['probsize'] == probsize), 'xtime'].iat[0]\n",
    "\t\t#\tposs = baselineXtimes.loc[(baselineXtimes['progname'] == progname) & (baselineXtimes['probsize'] == probsize), 'xtime']\n",
    "\t\t#\tprint('poss')\n",
    "\t\t#\tprint(poss)\n",
    "\t\t#\tstep = avrgCummax[avrgCummax['cummax'] >= val]['globalSample'].min()\n",
    "\t\t#\tif step is None:\n",
    "\t\t#\t\tprint(f'{progname} {probsize} {method} did not reach baseline')\n",
    "\t\t#\telse:\n",
    "\t\t#\t\tprint(f'{progname} {probsize} {method} passed baseline on step {step}')\n",
    "\t\t#\tprint('at step 280, avrgCummax is', avrgCummax[avrgCummax['globalSample'] == 280.0])\n",
    "\n",
    "\t\tif not ('optimal' in labels):\n",
    "\t\t\tax.set_title(f'{prognameMap[progname]} -- {probsizeMap[probsize]}')\n",
    "\t\t\tax.set_xlabel('Sample Index')\n",
    "\n",
    "\t\t\tif baselineXtimes is None:\n",
    "\t\t\t\t#ax.set_ylabel('Norm. to Optimal/Baseline Execution Times from Database \\n(higher is better)')\n",
    "\t\t\t\tax.axhline(baseline/optimal, c='blue', linestyle='--', zorder=0, label='optimal')\n",
    "\t\t\t\tax.axhline(1.0, c='red', linestyle='--', zorder=0, label='baseline')\n",
    "\t\t\t\t# what step do we pass the baseline xtime?\n",
    "\t\t\telse:\n",
    "\t\t\t\t#ax.set_ylabel('Norm. to Optimal/Worst Execution Times from Database \\n(higher is better)')\n",
    "\t\t\t\tval = baselineXtimes.loc[(baselineXtimes['progname'] == progname) & (baselineXtimes['probsize'] == probsize), 'xtime'].iat[0]\n",
    "\t\t\t\tax.axhline(1.0, c='blue', linestyle='--', zorder=0, label='optimal')\n",
    "\t\t\t\tax.axhline(val, c='red', linestyle='--', zorder=0, label='baseline')\n",
    "\n",
    "\t\t#ax.legend(loc='lower right')\n",
    "\t\treturn\n",
    "\n",
    "\tg = sns.FacetGrid(df, row='progname', col='probsize', col_order=probsizes, hue='method', \n",
    "\t\t\t\t\t\t\t\t\t\tpalette='flare', legend_out=False, height=5, aspect=1.5, sharex=False, sharey=False)\n",
    "\tg.map_dataframe(sns.lineplot, x='globalSample', y='cummax', errorbar=\"pi\")\n",
    "\tg.map_dataframe(addBaselines)\n",
    "\t#g.set(ylim=(-0.05, 1.05))\n",
    "\n",
    "\taxes = g.axes\n",
    "\tfor r in range(axes.shape[0]):\n",
    "\t\tif baselineXtimes is None:\n",
    "\t\t\taxes[r,0].set_ylabel('Norm. to Baseline from Database (Speedup) \\n( >1.0 is better )')\n",
    "\t\telse:\n",
    "\t\t\taxes[r,0].set_ylabel('Norm. to Optimal/Worst Execution Times from Database \\n(higher is better)')\n",
    "\t\tfor c in range(axes.shape[1]):\n",
    "\t\t\taxes[r,c].legend(loc='lower right')\n",
    "\n",
    "\tplt.tight_layout()\n",
    "\n",
    "\tg.fig.subplots_adjust(top=0.95)\n",
    "\tg.fig.suptitle('Average highest normalized execution time found at each optimization step')\n",
    "\n",
    "\tplt.show()\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "useBaseline=True\n",
    "\n",
    "overallDF = pd.DataFrame()\n",
    "tojoin = []\n",
    "for progname in prognames:\n",
    "\tif progname == 'cg_nas' or progname == 'cfd_rodinia':\n",
    "\t\tcontinue\n",
    "\tfor method in goMethods:\n",
    "\t\t# read the pre-processed dataframe\n",
    "\t\tif useBaseline:\n",
    "\t\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data-baselineNorm.csv'\n",
    "\t\telse:\n",
    "\t\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data.csv'\n",
    "\t\tfullDF = pd.read_csv(filename)\n",
    "\t\ttojoin += [fullDF]\n",
    "\n",
    "overallDF = pd.concat(tojoin, ignore_index=True, sort=True)\n",
    "overallDF = overallDF.drop(['optimXtime', 'kappa_decay', 'kappa_decay_delay'], axis=1)\n",
    "\n",
    "print(overallDF.columns)\n",
    "# for the method column, make all the bo entries a union of the method and utilFnct\n",
    "#overallDF[overallDF['method'] == 'bo'].apply(lambda x: x['method']+'-'+x['utilFnct'], axis=1)\n",
    "#print('it works')\n",
    "overallDF.loc[overallDF['method'] == 'bo', 'method'] = overallDF[overallDF['method'] == 'bo'].apply(lambda x: x['method']+'-'+x['utilFnct'], axis=1)\n",
    "#print(overallDF['method'].unique())\n",
    "\n",
    "overallDF = overallDF.drop(['utilFnct'], axis=1)\n",
    "\n",
    "for col in overallDF:\n",
    "\tif col == 'xtime' or col == 'globalSample' or col == 'optimXtime':\n",
    "\t\tcontinue\n",
    "\tprint(col, overallDF[col].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "baselinesDF = xtimeDB[(xtimeDB['OMP_NUM_THREADS'] == numthreads) \n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_PROC_BIND'] == 'close')\n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_PLACES'] == 'threads')\n",
    "\t\t\t\t\t\t\t\t\t\t& (xtimeDB['OMP_SCHEDULE'] == 'static')]\n",
    "\n",
    "def normToMinMax(row):\n",
    "\tprogname = row['progname']\n",
    "\tprobsize = row['probsize']\n",
    "\n",
    "\tminVal, maxVal = getMinMaxXtimeForProg(progname, probsize)\n",
    "\n",
    "\trow['xtime'] = 1 - (row['xtime']-minVal)/(maxVal-minVal)\n",
    "\treturn row\n",
    "\n",
    "\n",
    "# normalize the baselinesDF to the min/max\n",
    "baselinesDF.loc[:,'xtime'] = baselinesDF.apply(normToMinMax, axis=1)['xtime']\n",
    "\n",
    "if useBaseline:\n",
    "\tmakeOverallPlots(overallDF)\n",
    "else:\n",
    "\tmakeOverallPlots(overallDF,baselinesDF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10.8-gregvirtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
