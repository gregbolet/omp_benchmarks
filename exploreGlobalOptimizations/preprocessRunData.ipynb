{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from benchmarks import *\n",
    "import glob\n",
    "import os, sys\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', 5000)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MACHINE = 'lassen' if 'lassen' in ROOT_DIR else 'ruby'\n",
    "print(MACHINE, ROOT_DIR)\n",
    "prognames = list(progs.keys())\n",
    "prognames = ['bt_nas']\n",
    "probsizes = ['smlprob', 'medprob', 'lrgprob']\n",
    "probsizes = ['smlprob']\n",
    "\n",
    "logsDir = ROOT_DIR+'/logs'\n",
    "\n",
    "goMethods=['cma', 'pso', 'bo']\n",
    "seeds = [1337, 3827, 9999, 4873]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getHypersFromFilename(filename):\n",
    "\n",
    "\t# cut the path out if it has a path, and remove the .csv extension\n",
    "\tfilename = os.path.splitext(os.path.basename(filename))[0]\n",
    "\n",
    "\tif '-BO-' in filename:\n",
    "\t\tif '-ucb-' in filename:\n",
    "\t\t\tfilename = filename[filename.find('-ucb-')+5:]\n",
    "\t\t\tfound = re.findall(r'(?:k)(.*)(?:-kd)(.*)(?:-kdd)(.*)(?:--DONE)',filename)[0]\n",
    "\t\t\tk = float(found[0])\n",
    "\t\t\tkd = float(found[1])\n",
    "\t\t\tkdd = int(found[2])\n",
    "\t\t\treturn {'utilFnct':'ucb', 'kappa':k, 'kappa_decay':kd, 'kappa_decay_delay':kdd}\n",
    "\t\t\n",
    "\t\telif '-ei-' in filename:\n",
    "\t\t\tfilename = filename[filename.find('-ei-')+4:]\n",
    "\t\t\tfound = re.findall(r'(?:xi)(.*)(?:--DONE)',filename)[0]\n",
    "\t\t\txi = float(found)\n",
    "\t\t\treturn {'utilFnct':'ei', 'xi':xi}\n",
    "\t\t\n",
    "\t\telif '-poi-' in filename:\n",
    "\t\t\tfilename = filename[filename.find('-poi-')+5:]\n",
    "\t\t\tfound = re.findall(r'(?:xi)(.*)(?:--DONE)',filename)[0]\n",
    "\t\t\txi = float(found)\n",
    "\t\t\treturn {'utilFnct':'poi', 'xi':xi}\n",
    "\n",
    "\telif '-PSO-' in filename:\n",
    "\t\t\tfilename = filename[filename.find('-PSO-')+5:]\n",
    "\t\t\tfound = re.findall(r'(?:pop)(.*)(?:-w)(.*)(?:-c1)(.*)(?:-c2)(.*)(?:--DONE)',filename)[0]\n",
    "\t\t\tpop = int(found[0])\n",
    "\t\t\tw = float(found[1])\n",
    "\t\t\tc1 = float(found[2])\n",
    "\t\t\tc2 = float(found[3])\n",
    "\t\t\treturn {'popsize':pop, 'w':w, 'c1':c1, 'c2':c2}\n",
    "\t\n",
    "\telif '-CMA-' in filename:\n",
    "\t\t\tfilename = filename[filename.find('-CMA-')+5:]\n",
    "\t\t\tfound = re.findall(r'(?:sigma)(.*)(?:-pop)(.*)(?:-popdecay)(.*)(?:--DONE)',filename)[0]\n",
    "\t\t\tsigma = float(found[0])\n",
    "\t\t\tpop = int(found[1])\n",
    "\t\t\tpd = float(found[2])\n",
    "\t\t\t#return {'method':'cma', 'sigma':sigma, 'popsize':pop, 'popdecay':pd}\n",
    "\t\t\t# excluded popdecay in experiments\n",
    "\t\t\treturn {'sigma':sigma, 'popsize':pop}\n",
    "\t\n",
    "\telse:\n",
    "\t\tprint('no GO method in filename...')\n",
    "\t\traise ValueError('Failed to provide a string path with a GO Method')\n",
    "\t\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getData(progname, probsize, method, seed):\n",
    "\tmainDF = pd.DataFrame(columns=['progname', 'probsize', 'method', 'seed'])\n",
    "\tstartTime = time.time()\n",
    "\n",
    "\tdir = logsDir+f'/{progname}-{probsize}/{method}-{seed}'\n",
    "\tprint('working on', dir)\n",
    "\t# check that the directory exists\n",
    "\t# grab the completed data\n",
    "\tcsvs = glob.glob(dir+'/*DONE.csv')\n",
    "\n",
    "\t#print(f'{progname}-{probsize}/{method}-{seed} first 5')\n",
    "\t# print out the first step of the first CSVs, should be the same\n",
    "\n",
    "\t#for i in [0,1,6,10]:\n",
    "\t#\tcsv = pd.read_csv(csvs[i])\n",
    "\t#\tprint(csvs[i])\n",
    "\t#\tprint(csv.head(1))\n",
    "\n",
    "\t# read in each of the dataframe, then contatenate them all at once\n",
    "\treadin = []\n",
    "\tfor csv in tqdm(csvs):\n",
    "\t\t# extract the hyperparam values from the filename\n",
    "\t\thypers = getHypersFromFilename(csv)\n",
    "\t\t#toadd = pd.read_csv(csv, usecols=['globalSample', 'optimXtime', 'xtime'])\n",
    "\t\ttoadd = pd.read_csv(csv)\n",
    "\n",
    "\t\t# add the extra columns\n",
    "\t\tfor hyper,val in hypers.items():\n",
    "\t\t\ttoadd[hyper] = val\n",
    "\n",
    "\t\treadin += [toadd]\n",
    "\n",
    "\tmainDF = pd.concat([mainDF]+readin, ignore_index=True)\n",
    "\n",
    "\tmainDF['progname'] = progname\n",
    "\tmainDF['probsize'] = probsize\n",
    "\tmainDF['method'] = method\n",
    "\tmainDF['seed'] = seed \n",
    "\n",
    "\tprint(f'{progname}-{probsize}/{method}-{seed} starter configurations')\n",
    "\tif 'bo' in method:\n",
    "\t\tprint(mainDF[mainDF['globalSample'] == 0].drop_duplicates(ignore_index=True))\n",
    "\telse:\n",
    "\t\tprint(mainDF[mainDF['globalSample'] < mainDF['popsize']].drop_duplicates(ignore_index=True))\n",
    "\n",
    "\tprint('completed', progname, probsize, method, seed, mainDF.shape, (time.time() - startTime), 'secs')\t\t\n",
    "\treturn mainDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbFile = f'{MACHINE}-fullExploreDataset.csv'\n",
    "xtimeDB = pd.read_csv(ROOT_DIR+'/databases/'+dbFile)\n",
    "\n",
    "def getMinMaxXtimeForProg(progname, probsize):\n",
    "\tdf = xtimeDB[(xtimeDB['progname'] == progname) & \n",
    "\t\t\t\t\t\t\t (xtimeDB['probsize'] == probsize)]['xtime']\n",
    "\treturn (df.min(), df.max())\n",
    "\n",
    "# 0 will mean close to maxXtime\n",
    "# 1 will mean close to minXtime\n",
    "def convertXtimesToPercent(df, minXtime, maxXtime):\n",
    "\tnormed = (df['xtime']-minXtime)/(maxXtime-minXtime)\n",
    "\n",
    "\t# if any values are larger than 1, we need to cap them\n",
    "\t# this only happens if the max is smaller than an xtime (like when we baseline normalize)\n",
    "\tnormed = normed.apply(lambda x: 1.0 if x > 1.0 else x)\n",
    "\n",
    "\tdf['xtime'] = 1 - normed\n",
    "\treturn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessAllLogs(minMaxNorm=False, speedupNorm=False, onlyShowSeedHeads=False):\n",
    "\n",
    "\tassert not (minMaxNorm & speedupNorm)\n",
    "\n",
    "\tfor method in goMethods:\n",
    "\t\tfor progname in prognames:\n",
    "\t\t\t# gather all the data\n",
    "\t\t\ttoJoin = []\n",
    "\t\t\tfor probsize in probsizes:\n",
    "\t\t\t\tminXtime, maxXtime = getMinMaxXtimeForProg(progname, probsize)\n",
    "\t\t\t\tfor seed in seeds:\n",
    "\t\t\t\t\tdf = getData(progname, probsize, method, seed)\n",
    "\n",
    "\n",
    "\t\t\t\t\t# if there's no data\n",
    "\t\t\t\t\tif df.shape[0] == 0:\n",
    "\t\t\t\t\t\tcontinue\n",
    "\n",
    "\t\t\t\t\tif minMaxNorm:\n",
    "\t\t\t\t\t\tconvertXtimesToPercent(df, minXtime, maxXtime)\n",
    "\n",
    "\t\t\t\t\telif speedupNorm:\n",
    "\t\t\t\t\t\tnumthreads = 56 if MACHINE in 'ruby' else 80\n",
    "\t\t\t\t\t\tbaseline = xtimeDB[(xtimeDB['progname'] == progname)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t & (xtimeDB['probsize'] == probsize)\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t & (xtimeDB['OMP_NUM_THREADS'] == numthreads) \n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t & (xtimeDB['OMP_PROC_BIND'] == 'close')\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t & (xtimeDB['OMP_PLACES'] == 'cores')\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t & (xtimeDB['OMP_SCHEDULE'] == 'static')]\n",
    "\t\t\t\t\t\tassert baseline.shape[0] == 1\n",
    "\t\t\t\t\t\tbaselineVal = baseline['xtime'].iat[0]\n",
    "\t\t\t\t\t\tdf.loc[:,'xtime'] = baselineVal/df['xtime']\n",
    "\n",
    "\t\t\t\t\ttoJoin += [df]\n",
    "\n",
    "\n",
    "\t\t\t# if there's no data to join\n",
    "\t\t\tif len(toJoin) == 0:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tif onlyShowSeedHeads:\n",
    "\t\t\t\tcontinue\n",
    "\n",
    "\t\t\tfullDF = pd.concat(toJoin, ignore_index=True)\n",
    "\n",
    "\t\t\t# let's save the dataframe for future re-use\n",
    "\t\t\tif minMaxNorm:\n",
    "\t\t\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data-minMaxNorm.csv'\n",
    "\t\t\telif speedupNorm:\n",
    "\t\t\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data-baselineNorm.csv'\n",
    "\t\t\telse:\n",
    "\t\t\t\tfilename = ROOT_DIR+'/databases/'+f'{MACHINE}-{progname}-{method}-GO_Data-rawXtimes.csv'\n",
    "\t\t\tprint('\\n\\n wrote:', filename, '\\n\\n')\n",
    "\t\t\tfullDF.to_csv(filename, index=False)\n",
    "\treturn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessAllLogs(speedupNorm=True)\n",
    "#preprocessAllLogs(minMaxNorm=True)\n",
    "#preprocessAllLogs()\n",
    "preprocessAllLogs(onlyShowSeedHeads=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10.8-gregvirtenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
